I"Ú∞<p>I decided to take on the <a href="https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+">Occupancy dataset from UCI Machine Learning</a>. With this dataset, I wanted to accomplish 2 tasks:</p>

<ol>
  <li>Predict the occupancy of a room given parameters.</li>
  <li>Conduct Time Series Analysis to forecast the parameters and predict occupancy.</li>
</ol>

<p>The tasks may sound similar, but they‚Äôre actually different. The first one does not take the time into account, but rather uses the parameters or a subset of the parameters given (Light, Humidity, Temperature, CO2, etc.) to predict the occupancy of the room (binary -&gt; 0 or 1). The second task actually does take the time into account, and forecasts the individual parameters to predict the occupancy of the room at specific times where the parameters were forecast.</p>

<p>In this post, I am going to show how I tackle the first task. This example uses Python 3. 
First, import the required modules and packages:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">pandas</span> <span class="n">as</span> <span class="n">pd</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">metrics</span> <span class="n">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">plot_confusion_matrix</span>
<span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="nf">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">import</span> <span class="n">seaborn</span> <span class="n">as</span> <span class="n">sns</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">linear_model</span> <span class="n">import</span> <span class="no">LogisticRegression</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">neighbors</span> <span class="n">import</span> <span class="no">KNeighborsClassifier</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">naive_bayes</span> <span class="n">import</span> <span class="no">GaussianNB</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">neural_network</span> <span class="n">import</span> <span class="no">MLPClassifier</span>
<span class="n">from</span> <span class="n">sklearn</span> <span class="n">import</span> <span class="n">svm</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">feature_selection</span> <span class="n">import</span> <span class="no">SelectKBest</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">feature_selection</span> <span class="n">import</span> <span class="n">f_classif</span>
<span class="n">from</span> <span class="n">sklearn</span> <span class="n">import</span> <span class="n">preprocessing</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">tree</span> <span class="n">import</span> <span class="no">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">export_graphviz</span><span class="p">,</span><span class="n">plot_tree</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">ensemble</span> <span class="n">import</span> <span class="no">RandomForestClassifier</span>
<span class="n">from</span> <span class="n">statsmodels</span><span class="p">.</span><span class="nf">tsa</span><span class="p">.</span><span class="nf">seasonal</span> <span class="n">import</span> <span class="n">seasonal_decompose</span>
<span class="n">from</span> <span class="n">statsmodels</span><span class="p">.</span><span class="nf">tsa</span><span class="p">.</span><span class="nf">stattools</span> <span class="n">import</span> <span class="n">adfuller</span>
<span class="n">from</span> <span class="n">statsmodels</span><span class="p">.</span><span class="nf">tsa</span><span class="p">.</span><span class="nf">stattools</span> <span class="n">import</span> <span class="n">grangercausalitytests</span>
<span class="n">from</span> <span class="n">fbprophet</span> <span class="n">import</span> <span class="no">Prophet</span>
<span class="n">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]</span></code></pre></figure>

<p>Then, read in the data:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Read in data</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s1">'train_data.txt'</span><span class="p">)</span>
<span class="n">df_val</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s1">'validation_data.txt'</span><span class="p">)</span></code></pre></figure>

<p>Explore the data:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Explore data
</span><span class="n">df_train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Occupancy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>2015-02-04 17:51:00</td>
      <td>23.18</td>
      <td>27.2720</td>
      <td>426.0</td>
      <td>721.25</td>
      <td>0.004793</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2015-02-04 17:51:59</td>
      <td>23.15</td>
      <td>27.2675</td>
      <td>429.5</td>
      <td>714.00</td>
      <td>0.004783</td>
      <td>1</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2015-02-04 17:53:00</td>
      <td>23.15</td>
      <td>27.2450</td>
      <td>426.0</td>
      <td>713.50</td>
      <td>0.004779</td>
      <td>1</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2015-02-04 17:54:00</td>
      <td>23.15</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>708.25</td>
      <td>0.004772</td>
      <td>1</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2015-02-04 17:55:00</td>
      <td>23.10</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>704.50</td>
      <td>0.004757</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Occupancy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>8139</td>
      <td>2015-02-10 09:29:00</td>
      <td>21.05</td>
      <td>36.0975</td>
      <td>433.0</td>
      <td>787.250000</td>
      <td>0.005579</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8140</td>
      <td>2015-02-10 09:29:59</td>
      <td>21.05</td>
      <td>35.9950</td>
      <td>433.0</td>
      <td>789.500000</td>
      <td>0.005563</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8141</td>
      <td>2015-02-10 09:30:59</td>
      <td>21.10</td>
      <td>36.0950</td>
      <td>433.0</td>
      <td>798.500000</td>
      <td>0.005596</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8142</td>
      <td>2015-02-10 09:32:00</td>
      <td>21.10</td>
      <td>36.2600</td>
      <td>433.0</td>
      <td>820.333333</td>
      <td>0.005621</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8143</td>
      <td>2015-02-10 09:33:00</td>
      <td>21.10</td>
      <td>36.2000</td>
      <td>447.0</td>
      <td>821.000000</td>
      <td>0.005612</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>Data seems to be ordered by date and time and appropriate for time series analysis. Time intervals seem to be about every minute. Dates are from 2015-02-04 to 2015-02-10 (6 days).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 8143 entries, 1 to 8143
Data columns (total 7 columns):
date             8143 non-null object
Temperature      8143 non-null float64
Humidity         8143 non-null float64
Light            8143 non-null float64
CO2              8143 non-null float64
HumidityRatio    8143 non-null float64
Occupancy        8143 non-null int64
dtypes: float64(5), int64(1), object(1)
memory usage: 508.9+ KB
</code></pre></div></div>

<p>There are no null values in the training data. May need to convert date to datetime object. Occupancy is the only int type.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Occupancy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>8143.000000</td>
      <td>8143.000000</td>
      <td>8143.000000</td>
      <td>8143.000000</td>
      <td>8143.000000</td>
      <td>8143.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>20.619084</td>
      <td>25.731507</td>
      <td>119.519375</td>
      <td>606.546243</td>
      <td>0.003863</td>
      <td>0.212330</td>
    </tr>
    <tr>
      <td>std</td>
      <td>1.016916</td>
      <td>5.531211</td>
      <td>194.755805</td>
      <td>314.320877</td>
      <td>0.000852</td>
      <td>0.408982</td>
    </tr>
    <tr>
      <td>min</td>
      <td>19.000000</td>
      <td>16.745000</td>
      <td>0.000000</td>
      <td>412.750000</td>
      <td>0.002674</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>19.700000</td>
      <td>20.200000</td>
      <td>0.000000</td>
      <td>439.000000</td>
      <td>0.003078</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>20.390000</td>
      <td>26.222500</td>
      <td>0.000000</td>
      <td>453.500000</td>
      <td>0.003801</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>21.390000</td>
      <td>30.533333</td>
      <td>256.375000</td>
      <td>638.833333</td>
      <td>0.004352</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>23.180000</td>
      <td>39.117500</td>
      <td>1546.333333</td>
      <td>2028.500000</td>
      <td>0.006476</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Occupancy seems to be binary: either 0 or 1. Assume 1 means occupied, and 0 means unoccupied.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Convert date column to datetime object
</span><span class="n">df_train</span><span class="p">[</span><span class="s">'date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'date'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Verify changed datatype for date
</span><span class="n">df_train</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>date             datetime64[ns]
Temperature             float64
Humidity                float64
Light                   float64
CO2                     float64
HumidityRatio           float64
Occupancy                 int64
dtype: object
</code></pre></div></div>

<p>Date values are either at :00 or :59 seconds. Round all to nearest minute.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set date to index and round to nearest minute for time series analysis
</span><span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'date'</span><span class="p">)</span>
<span class="n">df_train</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="s">'min'</span><span class="p">)</span>
<span class="n">df_train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Occupancy</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2015-02-04 17:51:00</td>
      <td>23.18</td>
      <td>27.2720</td>
      <td>426.0</td>
      <td>721.25</td>
      <td>0.004793</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:52:00</td>
      <td>23.15</td>
      <td>27.2675</td>
      <td>429.5</td>
      <td>714.00</td>
      <td>0.004783</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:53:00</td>
      <td>23.15</td>
      <td>27.2450</td>
      <td>426.0</td>
      <td>713.50</td>
      <td>0.004779</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:54:00</td>
      <td>23.15</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>708.25</td>
      <td>0.004772</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:55:00</td>
      <td>23.10</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>704.50</td>
      <td>0.004757</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">plotting</span><span class="p">.</span><span class="n">register_matplotlib_converters</span><span class="p">()</span>
<span class="c1"># Plot all columns vs. date
</span><span class="n">df_train</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_14_0.png" alt="png" /></p>

<p>There appears to be some correlation between the variables, which can be seen from when the peaks occur. The occupancy seems less correlated to Humidity than it does with Light and CO2. Light seems to be the most important factor, since there are dips in the occupancy that coincide with dips in Light. There seems to be periodicity in the occupancy, where the occupancy can be 1 during ‚Äúnormal working hours‚Äù (i.e., 9am-6pm). However, there was no occupancy on 2 consecutive dates, 2015-02-07 and 2015-02-08. Perhaps those dates were the weekend, which indicates conditional seasonality. For those 2 dates, the CO2 levels were also very low with no peaks. Since the date range is small, assume no overall underlying trends in the variables. There also seems to be a high outlier in the Light data, with the value of 1546.3 within the day of 2015-02-07.</p>

<p>Check for Seasonality in parameters</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform seasonality decomposion for Temperature, period = 1 day
</span><span class="n">seas_d</span> <span class="o">=</span> <span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'Temperature'</span><span class="p">],</span> <span class="n">period</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">))</span>
<span class="n">fig</span><span class="o">=</span><span class="n">seas_d</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_17_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform seasonality decomposion for Light, period = 1 day
</span><span class="n">seas_d</span> <span class="o">=</span> <span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'Light'</span><span class="p">],</span> <span class="n">period</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">))</span>
<span class="n">fig</span><span class="o">=</span><span class="n">seas_d</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_18_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform seasonality decomposion for CO2, period = 1 day
</span><span class="n">seas_d</span> <span class="o">=</span> <span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'CO2'</span><span class="p">],</span> <span class="n">period</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">))</span>
<span class="n">fig</span><span class="o">=</span><span class="n">seas_d</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_19_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform seasonality decomposion for HumidityRatio, period = 1 day
</span><span class="n">seas_d</span> <span class="o">=</span> <span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'HumidityRatio'</span><span class="p">],</span> <span class="n">period</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">))</span>
<span class="n">fig</span><span class="o">=</span><span class="n">seas_d</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_20_0.png" alt="png" /></p>

<p>Perform Granger Causality Tests</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine Temperature causing Occupancy
</span><span class="k">print</span><span class="p">(</span><span class="n">grangercausalitytests</span><span class="p">(</span><span class="n">df_train</span><span class="p">[[</span><span class="s">'Occupancy'</span><span class="p">,</span> <span class="s">'Temperature'</span><span class="p">]],</span> <span class="n">maxlag</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Granger Causality
number of lags (no zero) 1
ssr based F test:         F=10.5156 , p=0.0012  , df_denom=8139, df_num=1
ssr based chi2 test:   chi2=10.5195 , p=0.0012  , df=1
likelihood ratio test: chi2=10.5127 , p=0.0012  , df=1
parameter F test:         F=10.5156 , p=0.0012  , df_denom=8139, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=3.5933  , p=0.0276  , df_denom=8136, df_num=2
ssr based chi2 test:   chi2=7.1910  , p=0.0274  , df=2
likelihood ratio test: chi2=7.1878  , p=0.0275  , df=2
parameter F test:         F=3.5933  , p=0.0276  , df_denom=8136, df_num=2

Granger Causality
number of lags (no zero) 3
ssr based F test:         F=1.1512  , p=0.3269  , df_denom=8133, df_num=3
ssr based chi2 test:   chi2=3.4566  , p=0.3264  , df=3
likelihood ratio test: chi2=3.4559  , p=0.3265  , df=3
parameter F test:         F=1.1512  , p=0.3269  , df_denom=8133, df_num=3

Granger Causality
number of lags (no zero) 4
ssr based F test:         F=0.6326  , p=0.6392  , df_denom=8130, df_num=4
ssr based chi2 test:   chi2=2.5331  , p=0.6387  , df=4
likelihood ratio test: chi2=2.5327  , p=0.6388  , df=4
parameter F test:         F=0.6326  , p=0.6392  , df_denom=8130, df_num=4
{1: ({'ssr_ftest': (10.515600218091105, 0.0011884805851629405, 8139.0, 1), 'ssr_chi2test': (10.51947622259464, 0.0011812295962018446, 1), 'lrtest': (10.512686480680713, 0.00118557768661934, 1), 'params_ftest': (10.515600218094972, 0.0011884805851604175, 8139.0, 1.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x1215440d0&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d909b90&gt;, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (3.5932701428753764, 0.02755189101173785, 8136.0, 2), 'ssr_chi2test': (7.190956792809351, 0.027447549225782523, 2), 'lrtest': (7.1877827706048265, 0.027491143374182788, 2), 'params_ftest': (3.5932701428739904, 0.02755189101177218, 8136.0, 2.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12153c350&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12195b110&gt;, array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (1.1512168877249138, 0.32689209422409926, 8133.0, 3), 'ssr_chi2test': (3.456623189258871, 0.326431677123941, 3), 'lrtest': (3.455889475357253, 0.3265283318868665, 3), 'params_ftest': (1.1512168877277935, 0.32689209422298965, 8133.0, 3.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121534e50&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d9090d0&gt;, array([[0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (0.6325826140788949, 0.6392277460576581, 8130.0, 4), 'ssr_chi2test': (2.533131560141759, 0.6387130628737945, 4), 'lrtest': (2.5327374439366395, 0.6387833973927893, 4), 'params_ftest': (0.6325826140901567, 0.6392277460497593, 8130.0, 4.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x1216f3f10&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8eca90&gt;, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}
</code></pre></div></div>

<p>For a lag &lt;= 2, the Temperature seems to cause Occupancy based on the Granger Causality Test p-value &lt; 0.05.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine Humidity causing Occupancy
</span><span class="k">print</span><span class="p">(</span><span class="n">grangercausalitytests</span><span class="p">(</span><span class="n">df_train</span><span class="p">[[</span><span class="s">'Occupancy'</span><span class="p">,</span> <span class="s">'Humidity'</span><span class="p">]],</span> <span class="n">maxlag</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Granger Causality
number of lags (no zero) 1
ssr based F test:         F=0.5782  , p=0.4471  , df_denom=8139, df_num=1
ssr based chi2 test:   chi2=0.5784  , p=0.4469  , df=1
likelihood ratio test: chi2=0.5784  , p=0.4470  , df=1
parameter F test:         F=0.5782  , p=0.4471  , df_denom=8139, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=1.3368  , p=0.2628  , df_denom=8136, df_num=2
ssr based chi2 test:   chi2=2.6752  , p=0.2625  , df=2
likelihood ratio test: chi2=2.6747  , p=0.2625  , df=2
parameter F test:         F=1.3368  , p=0.2628  , df_denom=8136, df_num=2

Granger Causality
number of lags (no zero) 3
ssr based F test:         F=0.6158  , p=0.6047  , df_denom=8133, df_num=3
ssr based chi2 test:   chi2=1.8490  , p=0.6043  , df=3
likelihood ratio test: chi2=1.8488  , p=0.6044  , df=3
parameter F test:         F=0.6158  , p=0.6047  , df_denom=8133, df_num=3

Granger Causality
number of lags (no zero) 4
ssr based F test:         F=0.9867  , p=0.4133  , df_denom=8130, df_num=4
ssr based chi2 test:   chi2=3.9510  , p=0.4127  , df=4
likelihood ratio test: chi2=3.9500  , p=0.4128  , df=4
parameter F test:         F=0.9867  , p=0.4133  , df_denom=8130, df_num=4
{1: ({'ssr_ftest': (0.5781720070298837, 0.44705175496434246, 8139.0, 1), 'ssr_chi2test': (0.578385118716957, 0.4469459998686701, 1), 'lrtest': (0.5783645762421656, 0.4469540697217348, 1), 'params_ftest': (0.5781720070245995, 0.44705175496647276, 8139.0, 1.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d909c10&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d909b90&gt;, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (1.336763770235409, 0.2627521241567607, 8136.0, 2), 'ssr_chi2test': (2.675170563787233, 0.26247871606533607, 2), 'lrtest': (2.6747311232975335, 0.26253639428940245, 2), 'params_ftest': (1.336763770238285, 0.2627521241561952, 8136.0, 2.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8ecb50&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8ecf50&gt;, array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (0.6158148460645417, 0.6046860128780425, 8133.0, 3), 'ssr_chi2test': (1.8490346171026817, 0.6043230239230211, 3), 'lrtest': (1.8488246409760904, 0.6043682147417089, 3), 'params_ftest': (0.6158148460645266, 0.6046860128780425, 8133.0, 3.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12153c350&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954ad0&gt;, array([[0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (0.9866551330898123, 0.4133429557230327, 8130.0, 4), 'ssr_chi2test': (3.950989484978097, 0.412679334524536, 4), 'lrtest': (3.9500308127244352, 0.41281068176994806, 4), 'params_ftest': (0.9866551331015199, 0.4133429557167153, 8130.0, 4.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954f50&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954c50&gt;, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}
</code></pre></div></div>

<p>The null hypothesis fails to be rejected at the p-value of 0.05, therefore Humidity does not cause Occupancy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine Light causing Occupancy
</span><span class="k">print</span><span class="p">(</span><span class="n">grangercausalitytests</span><span class="p">(</span><span class="n">df_train</span><span class="p">[[</span><span class="s">'Occupancy'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">]],</span> <span class="n">maxlag</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Granger Causality
number of lags (no zero) 1
ssr based F test:         F=216.6264, p=0.0000  , df_denom=8139, df_num=1
ssr based chi2 test:   chi2=216.7063, p=0.0000  , df=1
likelihood ratio test: chi2=213.8725, p=0.0000  , df=1
parameter F test:         F=216.6264, p=0.0000  , df_denom=8139, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=152.1224, p=0.0000  , df_denom=8136, df_num=2
ssr based chi2 test:   chi2=304.4318, p=0.0000  , df=2
likelihood ratio test: chi2=298.8777, p=0.0000  , df=2
parameter F test:         F=152.1224, p=0.0000  , df_denom=8136, df_num=2

Granger Causality
number of lags (no zero) 3
ssr based F test:         F=116.2704, p=0.0000  , df_denom=8133, df_num=3
ssr based chi2 test:   chi2=349.1115, p=0.0000  , df=3
likelihood ratio test: chi2=341.8325, p=0.0000  , df=3
parameter F test:         F=116.2704, p=0.0000  , df_denom=8133, df_num=3

Granger Causality
number of lags (no zero) 4
ssr based F test:         F=83.6931 , p=0.0000  , df_denom=8130, df_num=4
ssr based chi2 test:   chi2=335.1431, p=0.0000  , df=4
likelihood ratio test: chi2=328.4267, p=0.0000  , df=4
parameter F test:         F=83.6931 , p=0.0000  , df_denom=8130, df_num=4
{1: ({'ssr_ftest': (216.62642993560382, 2.0562395592856343e-48, 8139.0, 1), 'ssr_chi2test': (216.70627749547688, 4.7299069898945616e-49, 1), 'lrtest': (213.87253788191447, 1.9634670480476312e-48, 1), 'params_ftest': (216.62642993560408, 2.0562395592856343e-48, 8139.0, 1.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d909950&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x1215446d0&gt;, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (152.1223915307634, 1.3784532028737795e-65, 8136.0, 2), 'ssr_chi2test': (304.4317574857288, 7.824990229010475e-67, 2), 'lrtest': (298.8777013439758, 1.2575688495486277e-65, 2), 'params_ftest': (152.12239153065397, 1.3784532030197569e-65, 8136.0, 2.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954590&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954650&gt;, array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (116.27041836773999, 1.0028907212619656e-73, 8133.0, 3), 'ssr_chi2test': (349.1114738153462, 2.323097820054367e-75, 3), 'lrtest': (341.83245601379167, 8.752597933341622e-74, 3), 'params_ftest': (116.27041836773998, 1.0028907212628492e-73, 8133.0, 3.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x1215eb590&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954050&gt;, array([[0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (83.69313503029518, 9.349574743675364e-70, 8130.0, 4), 'ssr_chi2test': (335.1431370290639, 2.827331931643635e-71, 4), 'lrtest': (328.4267270025739, 7.963198645095444e-70, 4), 'params_ftest': (83.69313503028006, 9.349574743941627e-70, 8130.0, 4.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8f2650&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8f2290&gt;, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}
</code></pre></div></div>

<p>Light seems to have a strong effect on Occupancy, since p-value is 0.000.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine CO2 causing Occupancy
</span><span class="k">print</span><span class="p">(</span><span class="n">grangercausalitytests</span><span class="p">(</span><span class="n">df_train</span><span class="p">[[</span><span class="s">'Occupancy'</span><span class="p">,</span> <span class="s">'CO2'</span><span class="p">]],</span> <span class="n">maxlag</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Granger Causality
number of lags (no zero) 1
ssr based F test:         F=34.9532 , p=0.0000  , df_denom=8139, df_num=1
ssr based chi2 test:   chi2=34.9661 , p=0.0000  , df=1
likelihood ratio test: chi2=34.8912 , p=0.0000  , df=1
parameter F test:         F=34.9532 , p=0.0000  , df_denom=8139, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=12.9394 , p=0.0000  , df_denom=8136, df_num=2
ssr based chi2 test:   chi2=25.8947 , p=0.0000  , df=2
likelihood ratio test: chi2=25.8536 , p=0.0000  , df=2
parameter F test:         F=12.9394 , p=0.0000  , df_denom=8136, df_num=2

Granger Causality
number of lags (no zero) 3
ssr based F test:         F=5.3197  , p=0.0012  , df_denom=8133, df_num=3
ssr based chi2 test:   chi2=15.9727 , p=0.0011  , df=3
likelihood ratio test: chi2=15.9571 , p=0.0012  , df=3
parameter F test:         F=5.3197  , p=0.0012  , df_denom=8133, df_num=3

Granger Causality
number of lags (no zero) 4
ssr based F test:         F=2.7232  , p=0.0279  , df_denom=8130, df_num=4
ssr based chi2 test:   chi2=10.9050 , p=0.0277  , df=4
likelihood ratio test: chi2=10.8977 , p=0.0277  , df=4
parameter F test:         F=2.7232  , p=0.0279  , df_denom=8130, df_num=4
{1: ({'ssr_ftest': (34.95321142853135, 3.513441792672317e-09, 8139.0, 1), 'ssr_chi2test': (34.9660950302374, 3.3549665099567356e-09, 1), 'lrtest': (34.891227760119364, 3.486481577200691e-09, 1), 'params_ftest': (34.95321142828012, 3.5134417931224022e-09, 8139.0, 1.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d909b90&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121954650&gt;, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (12.939402174169055, 2.451361363274222e-06, 8136.0, 2), 'ssr_chi2test': (25.89470823498286, 2.3825144949992743e-06, 2), 'lrtest': (25.853612705301202, 2.4319762667379205e-06, 2), 'params_ftest': (12.939402174147045, 2.4513613633286006e-06, 8136.0, 2.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8f2b50&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8f2410&gt;, array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (5.319664402728529, 0.0011641746096933505, 8133.0, 3), 'ssr_chi2test': (15.97272897019927, 0.0011486767474718582, 3), 'lrtest': (15.957078183288104, 0.0011571939229575265, 3), 'params_ftest': (5.3196644026789315, 0.001164174609774549, 8133.0, 3.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d911710&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d911150&gt;, array([[0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (2.7232469552480016, 0.027863347815891896, 8130.0, 4), 'ssr_chi2test': (10.905046479096425, 0.027652144774908145, 4), 'lrtest': (10.897747430004529, 0.027737549191175867, 4), 'params_ftest': (2.723246955187612, 0.027863347818739642, 8130.0, 4.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121eeddd0&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d911950&gt;, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}
</code></pre></div></div>

<p>CO2 seems to have a strong effect on Occupancy, since p-value is &lt; 0.05 for max_lag &lt;= 4.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine HumidityRatio causing Occupancy
</span><span class="k">print</span><span class="p">(</span><span class="n">grangercausalitytests</span><span class="p">(</span><span class="n">df_train</span><span class="p">[[</span><span class="s">'Occupancy'</span><span class="p">,</span> <span class="s">'HumidityRatio'</span><span class="p">]],</span> <span class="n">maxlag</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Granger Causality
number of lags (no zero) 1
ssr based F test:         F=2.7994  , p=0.0943  , df_denom=8139, df_num=1
ssr based chi2 test:   chi2=2.8005  , p=0.0942  , df=1
likelihood ratio test: chi2=2.8000  , p=0.0943  , df=1
parameter F test:         F=2.7994  , p=0.0943  , df_denom=8139, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=1.7887  , p=0.1672  , df_denom=8136, df_num=2
ssr based chi2 test:   chi2=3.5797  , p=0.1670  , df=2
likelihood ratio test: chi2=3.5789  , p=0.1671  , df=2
parameter F test:         F=1.7887  , p=0.1672  , df_denom=8136, df_num=2

Granger Causality
number of lags (no zero) 3
ssr based F test:         F=0.7380  , p=0.5293  , df_denom=8133, df_num=3
ssr based chi2 test:   chi2=2.2158  , p=0.5289  , df=3
likelihood ratio test: chi2=2.2155  , p=0.5289  , df=3
parameter F test:         F=0.7380  , p=0.5293  , df_denom=8133, df_num=3

Granger Causality
number of lags (no zero) 4
ssr based F test:         F=0.9660  , p=0.4248  , df_denom=8130, df_num=4
ssr based chi2 test:   chi2=3.8683  , p=0.4241  , df=4
likelihood ratio test: chi2=3.8674  , p=0.4243  , df=4
parameter F test:         F=0.9660  , p=0.4248  , df_denom=8130, df_num=4
{1: ({'ssr_ftest': (2.7994495684347247, 0.09433510384211544, 8139.0, 1), 'ssr_chi2test': (2.8004814333696433, 0.0942360069980527, 1), 'lrtest': (2.799999924012809, 0.09426431130865497, 1), 'params_ftest': (2.799449568434711, 0.09433510384211544, 8139.0, 1.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8ec850&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12153c350&gt;, array([[0., 1., 0.]])]), 2: ({'ssr_ftest': (1.7887487294813864, 0.16723494858875154, 8136.0, 2), 'ssr_chi2test': (3.579696019348074, 0.16698554792622738, 2), 'lrtest': (3.578909232201113, 0.167051251890557, 2), 'params_ftest': (1.7887487294809006, 0.16723494858883073, 8136.0, 2.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d911b50&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d9115d0&gt;, array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.]])]), 3: ({'ssr_ftest': (0.7379510394387019, 0.5292573095580974, 8133.0, 3), 'ssr_chi2test': (2.2157585617967666, 0.5288510996267659, 3), 'lrtest': (2.215457044883806, 0.5289102360516149, 3), 'params_ftest': (0.7379510394391602, 0.5292573095579194, 8133.0, 3.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x1215348d0&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12d8f2e50&gt;, array([[0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0.]])]), 4: ({'ssr_ftest': (0.9660033188057995, 0.42478433188508447, 8130.0, 4), 'ssr_chi2test': (3.8682907806939246, 0.4241241083428684, 4), 'lrtest': (3.8673718144054874, 0.42425258322177695, 4), 'params_ftest': (0.9660033188159165, 0.4247843318793969, 8130.0, 4.0)}, [&lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x12196be90&gt;, &lt;statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x121709ad0&gt;, array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}
</code></pre></div></div>

<p>The null hypothesis fails to be rejected at the p-value of 0.05, therefore HumidityRatio does not cause Occupancy.</p>

<p>Check each parameter for stationarity using ADF Test</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check Temperature for stationarity
</span><span class="n">result</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'Temperature'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ADF Statistic: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'p-value: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Critical Values:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">%s: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ADF Statistic: -2.694434
p-value: 0.075006
Critical Values:
	1%: -3.431
	5%: -2.862
	10%: -2.567
</code></pre></div></div>

<p>The p-value is above the rule-of-thumb threshold of 0.05, indicating that there is a unit root, and Temperature is NOT stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check Humidity for stationarity
</span><span class="n">result</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'Humidity'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ADF Statistic: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'p-value: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Critical Values:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">%s: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ADF Statistic: -0.751632
p-value: 0.832919
Critical Values:
	1%: -3.431
	5%: -2.862
	10%: -2.567
</code></pre></div></div>

<p>The p-value is above the rule-of-thumb threshold of 0.05, indicating that there is a unit root, and Humidity is NOT stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check Light for stationarity
</span><span class="n">result</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'Light'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ADF Statistic: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'p-value: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Critical Values:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">%s: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ADF Statistic: -3.314650
p-value: 0.014236
Critical Values:
	1%: -3.431
	5%: -2.862
	10%: -2.567
</code></pre></div></div>

<p>The p-value is below the rule-of-thumb threshold of 0.05, indicating that there is no unit root, and Light IS stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check CO2 for stationarity
</span><span class="n">result</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'CO2'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ADF Statistic: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'p-value: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Critical Values:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">%s: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ADF Statistic: -3.639003
p-value: 0.005058
Critical Values:
	1%: -3.431
	5%: -2.862
	10%: -2.567
</code></pre></div></div>

<p>The p-value is below the rule-of-thumb threshold of 0.05, indicating that there is no unit root, and CO2 IS stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check HumidityRatio for stationarity
</span><span class="n">result</span> <span class="o">=</span> <span class="n">adfuller</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'HumidityRatio'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ADF Statistic: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'p-value: %f'</span> <span class="o">%</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Critical Values:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="mi">4</span><span class="p">].</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">%s: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ADF Statistic: -1.279709
p-value: 0.638403
Critical Values:
	1%: -3.431
	5%: -2.862
	10%: -2.567
</code></pre></div></div>

<p>The p-value is above the rule-of-thumb threshold of 0.05, indicating that there is a unit root, and HumidityRatio is NOT stationary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine hours for Occupancy=1
</span><span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">5</span><span class="p">][</span><span class="s">'Occupancy'</span><span class="p">].</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_43_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">6</span><span class="p">][</span><span class="s">'Occupancy'</span><span class="p">].</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_44_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">9</span><span class="p">][</span><span class="s">'Occupancy'</span><span class="p">].</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_45_0.png" alt="png" /></p>

<p>The plots confirm that the hours for occupancy tend to be roughly between 9am-6pm.</p>

<p>Since the day of the week and time of the day seem to be important factors in predicting occupancy and trends in the other variables, create new columns for ‚ÄúWorkHours‚Äù and ‚ÄúWeekday‚Äù</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Separate X and y
</span><span class="n">X_df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">y_df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s">'Occupancy'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Add binary column for Weekday
</span><span class="n">X_df_train</span><span class="p">[</span><span class="s">'Weekday'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">7</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">8</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Add binary column for WorkHours
</span><span class="n">X_df_train</span><span class="p">[</span><span class="s">'WorkHours'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">hour</span> <span class="o">&gt;=</span> <span class="mi">8</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_train</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Weekday</th>
      <th>WorkHours</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2015-02-04 17:51:00</td>
      <td>23.18</td>
      <td>27.2720</td>
      <td>426.0</td>
      <td>721.250000</td>
      <td>0.004793</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:52:00</td>
      <td>23.15</td>
      <td>27.2675</td>
      <td>429.5</td>
      <td>714.000000</td>
      <td>0.004783</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:53:00</td>
      <td>23.15</td>
      <td>27.2450</td>
      <td>426.0</td>
      <td>713.500000</td>
      <td>0.004779</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:54:00</td>
      <td>23.15</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>708.250000</td>
      <td>0.004772</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2015-02-04 17:55:00</td>
      <td>23.10</td>
      <td>27.2000</td>
      <td>426.0</td>
      <td>704.500000</td>
      <td>0.004757</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>2015-02-10 09:29:00</td>
      <td>21.05</td>
      <td>36.0975</td>
      <td>433.0</td>
      <td>787.250000</td>
      <td>0.005579</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-10 09:30:00</td>
      <td>21.05</td>
      <td>35.9950</td>
      <td>433.0</td>
      <td>789.500000</td>
      <td>0.005563</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-10 09:31:00</td>
      <td>21.10</td>
      <td>36.0950</td>
      <td>433.0</td>
      <td>798.500000</td>
      <td>0.005596</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-10 09:32:00</td>
      <td>21.10</td>
      <td>36.2600</td>
      <td>433.0</td>
      <td>820.333333</td>
      <td>0.005621</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-10 09:33:00</td>
      <td>21.10</td>
      <td>36.2000</td>
      <td>447.0</td>
      <td>821.000000</td>
      <td>0.005612</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>8143 rows √ó 7 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine outlier for Light
</span><span class="n">X_df_train</span><span class="p">[</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">7</span><span class="p">][</span><span class="s">'Light'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_52_0.png" alt="png" /></p>

<p>This is most likely an error, so we‚Äôll assume that the data for that spike can be removed and imputed.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Find time when spike occurred
</span><span class="n">X_df_train</span><span class="p">[(</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">7</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">hour</span> <span class="o">==</span> <span class="mi">9</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_df_train</span><span class="p">[</span><span class="s">'Light'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">400</span><span class="p">)][</span><span class="s">'Light'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>date
2015-02-07 09:41:00     611.500000
2015-02-07 09:42:00    1546.333333
2015-02-07 09:43:00    1451.750000
2015-02-07 09:44:00     829.000000
Name: Light, dtype: float64
</code></pre></div></div>

<p>The data for Light was unusually high for 4 data points (09:40:59 through 09:43:59). To improve training the model, we‚Äôll change these values by imputing using simple linear regression.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Replace high values with NaN
</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="s">'2015-02-07 09:41:00'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>
<span class="n">X_df_train</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="s">'2015-02-07 09:42:00'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>
<span class="n">X_df_train</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="s">'2015-02-07 09:43:00'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>
<span class="n">X_df_train</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="s">'2015-02-07 09:44:00'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Interpolate NaN values using simple linear regression
</span><span class="n">X_df_train</span><span class="p">[</span><span class="s">'Light'</span><span class="p">].</span><span class="n">interpolate</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Verify values were imputed
</span><span class="n">X_df_train</span><span class="p">[</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">7</span><span class="p">][</span><span class="s">'Light'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_58_0.png" alt="png" /></p>

<p>CO2 also had some unusually high spikes near the end of the day on 2015-02-09. Let‚Äôs zoom in and examine it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine spikes for CO2
</span><span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">9</span><span class="p">][</span><span class="s">'CO2'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_60_0.png" alt="png" /></p>

<p>However, the spike for CO2 is still in the range of the data, so we‚Äôll keep it and not bother smoothing it for now.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine correlation matrix for predicting variables
</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Weekday</th>
      <th>WorkHours</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Temperature</td>
      <td>1.000000</td>
      <td>-0.141759</td>
      <td>0.654502</td>
      <td>0.559894</td>
      <td>0.151762</td>
      <td>0.418657</td>
      <td>0.532213</td>
    </tr>
    <tr>
      <td>Humidity</td>
      <td>-0.141759</td>
      <td>1.000000</td>
      <td>0.040864</td>
      <td>0.439023</td>
      <td>0.955198</td>
      <td>0.108551</td>
      <td>-0.327712</td>
    </tr>
    <tr>
      <td>Light</td>
      <td>0.654502</td>
      <td>0.040864</td>
      <td>1.000000</td>
      <td>0.670003</td>
      <td>0.234770</td>
      <td>0.284592</td>
      <td>0.404677</td>
    </tr>
    <tr>
      <td>CO2</td>
      <td>0.559894</td>
      <td>0.439023</td>
      <td>0.670003</td>
      <td>1.000000</td>
      <td>0.626556</td>
      <td>0.394834</td>
      <td>0.201954</td>
    </tr>
    <tr>
      <td>HumidityRatio</td>
      <td>0.151762</td>
      <td>0.955198</td>
      <td>0.234770</td>
      <td>0.626556</td>
      <td>1.000000</td>
      <td>0.243146</td>
      <td>-0.167921</td>
    </tr>
    <tr>
      <td>Weekday</td>
      <td>0.418657</td>
      <td>0.108551</td>
      <td>0.284592</td>
      <td>0.394834</td>
      <td>0.243146</td>
      <td>1.000000</td>
      <td>0.462569</td>
    </tr>
    <tr>
      <td>WorkHours</td>
      <td>0.532213</td>
      <td>-0.327712</td>
      <td>0.404677</td>
      <td>0.201954</td>
      <td>-0.167921</td>
      <td>0.462569</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>The correlation matrix shows that Humidity and HumidityRatio are highly correlated, so one of these may potentially be removed from the model to reduce multicollinearity. CO2 and HumidityRatio seem somewhat correlated, too. Therefore, let us drop HumidityRatio from the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_train</span> <span class="o">=</span> <span class="n">X_df_train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s">'HumidityRatio'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Examine correlation matrix after dropping HumidityRatio
</span><span class="n">X_df_train</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>Weekday</th>
      <th>WorkHours</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Temperature</td>
      <td>1.000000</td>
      <td>-0.141759</td>
      <td>0.654502</td>
      <td>0.559894</td>
      <td>0.418657</td>
      <td>0.532213</td>
    </tr>
    <tr>
      <td>Humidity</td>
      <td>-0.141759</td>
      <td>1.000000</td>
      <td>0.040864</td>
      <td>0.439023</td>
      <td>0.108551</td>
      <td>-0.327712</td>
    </tr>
    <tr>
      <td>Light</td>
      <td>0.654502</td>
      <td>0.040864</td>
      <td>1.000000</td>
      <td>0.670003</td>
      <td>0.284592</td>
      <td>0.404677</td>
    </tr>
    <tr>
      <td>CO2</td>
      <td>0.559894</td>
      <td>0.439023</td>
      <td>0.670003</td>
      <td>1.000000</td>
      <td>0.394834</td>
      <td>0.201954</td>
    </tr>
    <tr>
      <td>Weekday</td>
      <td>0.418657</td>
      <td>0.108551</td>
      <td>0.284592</td>
      <td>0.394834</td>
      <td>1.000000</td>
      <td>0.462569</td>
    </tr>
    <tr>
      <td>WorkHours</td>
      <td>0.532213</td>
      <td>-0.327712</td>
      <td>0.404677</td>
      <td>0.201954</td>
      <td>0.462569</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Inspect df_val:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_val</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 9752 entries, 1 to 9752
Data columns (total 7 columns):
date             9752 non-null object
Temperature      9752 non-null float64
Humidity         9752 non-null float64
Light            9752 non-null float64
CO2              9752 non-null float64
HumidityRatio    9752 non-null float64
Occupancy        9752 non-null int64
dtypes: float64(5), int64(1), object(1)
memory usage: 609.5+ KB
</code></pre></div></div>

<p>Again, no null values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_val</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>HumidityRatio</th>
      <th>Occupancy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>9752.000000</td>
      <td>9752.000000</td>
      <td>9752.000000</td>
      <td>9752.000000</td>
      <td>9752.000000</td>
      <td>9752.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>21.001768</td>
      <td>29.891910</td>
      <td>123.067930</td>
      <td>753.224832</td>
      <td>0.004589</td>
      <td>0.210111</td>
    </tr>
    <tr>
      <td>std</td>
      <td>1.020693</td>
      <td>3.952844</td>
      <td>208.221275</td>
      <td>297.096114</td>
      <td>0.000531</td>
      <td>0.407408</td>
    </tr>
    <tr>
      <td>min</td>
      <td>19.500000</td>
      <td>21.865000</td>
      <td>0.000000</td>
      <td>484.666667</td>
      <td>0.003275</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>20.290000</td>
      <td>26.642083</td>
      <td>0.000000</td>
      <td>542.312500</td>
      <td>0.004196</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>20.790000</td>
      <td>30.200000</td>
      <td>0.000000</td>
      <td>639.000000</td>
      <td>0.004593</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>21.533333</td>
      <td>32.700000</td>
      <td>208.250000</td>
      <td>831.125000</td>
      <td>0.004998</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>24.390000</td>
      <td>39.500000</td>
      <td>1581.000000</td>
      <td>2076.500000</td>
      <td>0.005769</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Convert date column to datetime object and set as index, round to nearest minute
</span><span class="n">df_val</span><span class="p">[</span><span class="s">'date'</span><span class="p">]</span> <span class="o">=</span>  <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_val</span><span class="p">[</span><span class="s">'date'</span><span class="p">])</span>
<span class="n">df_val</span> <span class="o">=</span> <span class="n">df_val</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'date'</span><span class="p">)</span>
<span class="n">df_val</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="s">'min'</span><span class="p">)</span>

<span class="c1"># Plot df_val to visualize
</span><span class="n">df_val</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">subplots</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_70_0.png" alt="png" /></p>

<p>It can be seen that this is a continuation of the time series data from the training set. Now, the dates 2015-02-11 to 2015-02-19 are given. The same seasonality pattern of no occupancy for 2 consecutive days (2015-02-14 and 2015-02-15) can be observed, which indicates conditional seasonality. Add columns for Weekday or Weekend and Hour to take into account this seasonality for predicting Occupancy. Also, note that the time range is quite short here, and none of the variables lead us to predict that there is a trend component to this time series. Therefore, assume there is no trend component.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Drop HumidityRatio from df_val
</span><span class="n">df_val</span> <span class="o">=</span> <span class="n">df_val</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s">'HumidityRatio'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Separate X and y
</span><span class="n">X_df_val</span> <span class="o">=</span> <span class="n">df_val</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">4</span><span class="p">]</span>
<span class="n">y_df_val</span> <span class="o">=</span> <span class="n">df_val</span><span class="p">[</span><span class="s">'Occupancy'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Add columns for Weekday and WorkHours
</span><span class="n">X_df_val</span><span class="p">[</span><span class="s">'Weekday'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">X_df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">14</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">X_df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">==</span> <span class="mi">15</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_df_val</span><span class="p">[</span><span class="s">'WorkHours'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">X_df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">hour</span> <span class="o">&gt;=</span> <span class="mi">8</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X_df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">hour</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>Split the validation set into validation set for comparing models and test set for assessing model accuracy. Use dates from 2015-02-11 to 2015-02-14 for validation set, and 2015-02-15 to 2015-02-18 for test set. This gives a good balance by including a date in each set with a ‚Äúweekend‚Äù day, and makes the test set the latest set in time.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_test</span> <span class="o">=</span> <span class="n">X_df_val</span><span class="p">[</span><span class="n">df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">y_df_test</span> <span class="o">=</span> <span class="n">y_df_val</span><span class="p">[</span><span class="n">df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">X_df_val</span> <span class="o">=</span> <span class="n">X_df_val</span><span class="p">[</span><span class="n">df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">]</span>
<span class="n">y_df_val</span> <span class="o">=</span> <span class="n">y_df_val</span><span class="p">[</span><span class="n">df_val</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">day</span> <span class="o">&lt;=</span> <span class="mi">14</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_val</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>Weekday</th>
      <th>WorkHours</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2015-02-11 14:48:00</td>
      <td>21.7600</td>
      <td>31.133333</td>
      <td>437.333333</td>
      <td>1029.666667</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-11 14:49:00</td>
      <td>21.7900</td>
      <td>31.000000</td>
      <td>437.333333</td>
      <td>1000.000000</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-11 14:50:00</td>
      <td>21.7675</td>
      <td>31.122500</td>
      <td>434.000000</td>
      <td>1003.750000</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-11 14:51:00</td>
      <td>21.7675</td>
      <td>31.122500</td>
      <td>439.000000</td>
      <td>1009.500000</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-11 14:52:00</td>
      <td>21.7900</td>
      <td>31.133333</td>
      <td>437.333333</td>
      <td>1005.666667</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_df_val</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>date
2015-02-11 14:48:00    1
2015-02-11 14:49:00    1
2015-02-11 14:50:00    1
2015-02-11 14:51:00    1
2015-02-11 14:52:00    1
Name: Occupancy, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_test</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Light</th>
      <th>CO2</th>
      <th>Weekday</th>
      <th>WorkHours</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2015-02-15 00:00:00</td>
      <td>19.89</td>
      <td>35.745</td>
      <td>0.0</td>
      <td>535.500000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-15 00:01:00</td>
      <td>19.89</td>
      <td>35.700</td>
      <td>0.0</td>
      <td>541.000000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-15 00:02:00</td>
      <td>20.00</td>
      <td>35.700</td>
      <td>0.0</td>
      <td>539.333333</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-15 00:03:00</td>
      <td>20.00</td>
      <td>35.700</td>
      <td>0.0</td>
      <td>541.000000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2015-02-15 00:04:00</td>
      <td>20.00</td>
      <td>35.700</td>
      <td>0.0</td>
      <td>542.000000</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_df_test</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>date
2015-02-15 00:00:00    0
2015-02-15 00:01:00    0
2015-02-15 00:02:00    0
2015-02-15 00:03:00    0
2015-02-15 00:04:00    0
Name: Occupancy, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Normalize appropriate columns for building Classification Models
</span><span class="n">cols_to_norm</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Temperature'</span><span class="p">,</span> <span class="s">'Humidity'</span><span class="p">,</span> <span class="s">'Light'</span><span class="p">,</span> <span class="s">'CO2'</span><span class="p">]</span>
<span class="n">X_df_train</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df_train</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_df_val</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df_val</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
<span class="n">X_df_test</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df_test</span><span class="p">[</span><span class="n">cols_to_norm</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_df_train</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_df_train</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_df_val</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_df_val</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Implement Logistic Regression
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s">'lbfgs'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="c1"># Fit model: Predict y from x_test after training on x_train and y_train
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">).</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># Report testing accuracy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.811576
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Implement the Gaussian Naive Bayes algorithm for classification
</span><span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="c1"># Fit model: Predict y from x_test after training on x_train and y_train
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">).</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># Report testing accuracy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.888547
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Implement KNN
</span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#Best: n_neighbors=3
# Fit model: Predict y from x_test after training on x_train and y_train
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">).</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># Report testing accuracy
</span><span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.932471
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Build classifier using svm
</span><span class="n">SVM</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s">'rbf'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1">#Best: C=1, kernel = 'rbf'
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">SVM</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.991379
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Build classifier using simple neural network
</span><span class="n">NN</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">learning_rate_init</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">99</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">NN</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.837233
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Build classifier using CART
</span><span class="n">dct</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">99</span><span class="p">)</span>
<span class="n">dct</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dct</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.880747
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot decision tree to view feature importances
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> <span class="c1">#Set figure size for legibility
</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">dct</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_90_0.png" alt="png" /></p>

<p>The Decision Tree plot shows that X[2] (Light) is the most important feature, followed by X[3] (CO2) and X[0] (Temperature).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Build classifier using Random Forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">99</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4872 points : 0.838259
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate feature importances
</span><span class="n">importances</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="k">print</span><span class="p">(</span><span class="n">importances</span><span class="p">)</span>

<span class="c1"># Sort feature importances in descending order
</span><span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.06784078 0.02669683 0.64817013 0.21166027 0.01187343 0.03375856]
[2 3 0 5 1 4]
</code></pre></div></div>

<p>The rank and weights of the features from the Random Forest classifier confirm that X[2] (Light) is the most important feature.</p>

<h4 id="svm-model-with-c1-and-kernelrbf-performed-the-best-on-the-validation-set-assess-the-true-accuracy-of-the-model-using-the-test-set">SVM model with C=1 and kernel=‚Äôrbf‚Äô performed the best on the validation set. Assess the true accuracy of the model using the test set.</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_test</span> <span class="o">=</span> <span class="n">X_df_test</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_df_test</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Build classifier using svm
</span><span class="n">SVM</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s">'rbf'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1">#Best: C=1, kernel = 'rbf'
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">SVM</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Testing accuracy out of a total %d points : %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing accuracy out of a total 4880 points : 0.996107
</code></pre></div></div>

<p>The accuracy on the test set is 0.996107, which is very high!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot confusion matrix
</span><span class="n">titles_options</span> <span class="o">=</span> <span class="p">[(</span><span class="s">"Confusion matrix, without normalization"</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span>
                  <span class="p">(</span><span class="s">"Normalized confusion matrix"</span><span class="p">,</span> <span class="s">'true'</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">title</span><span class="p">,</span> <span class="n">normalize</span> <span class="ow">in</span> <span class="n">titles_options</span><span class="p">:</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">SVM</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
                                 <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">,</span>
                                 <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="n">disp</span><span class="p">.</span><span class="n">ax_</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">disp</span><span class="p">.</span><span class="n">confusion_matrix</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion matrix, without normalization
[[3765   18]
 [   1 1096]]
Normalized confusion matrix
[[9.95241872e-01 4.75812847e-03]
 [9.11577028e-04 9.99088423e-01]]
</code></pre></div></div>

<p><img src="output_99_1.png" alt="png" /></p>

<p><img src="output_99_2.png" alt="png" /></p>

<h4 id="conclusion">Conclusion</h4>
<p>The model only predicts based on the variables Temperature, Humidity, CO2, Weekday, and WorkHours. It assumes that the information on the variables is known. For further exploration, subsets of the variables could be used to train more models. For a more difficult problem, forecast the variables and make predictions from the forecast, and compare the predictions with the actual results.</p>

:ET